{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for CIViC data\n",
    "\n",
    "This notebook contains an analysis on CIViC variant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kxk102/.local/share/virtualenvs/variation-normalization-KPVKcmjd/lib/python3.11/site-packages/python_jsonschema_objects/__init__.py:49: UserWarning: Schema version http://json-schema.org/draft-07/schema not recognized. Some keywords and features may not be supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from enum import Enum\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from civicpy import civic as civicpy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from variation.query import QueryHandler\n",
    "\n",
    "logging.getLogger(\"root\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Environment variables are set for gene-normalizer dynamodb instance and \n",
    "# UTA DB credentials\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_handler = QueryHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get latest data\n",
    "# civicpy.update_cache(from_remote_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "civicpy.load_cache(on_stale=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total Number of variants in CIViC: 3509'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variants = civicpy.get_all_variants()\n",
    "total_variants = len(variants)\n",
    "f\"Total Number of variants in CIViC: {total_variants}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariantCategory(str, Enum):\n",
    "    \"\"\"Create enum for the kind of variants that are in CIViC.\"\"\"\n",
    "    EXPRESSION = \"Expression\"\n",
    "    EPIGENETIC_MODIFICATION = \"Epigenetic Modification\"\n",
    "    FUSION = \"Fusion\"\n",
    "    PROTEIN_CONS = \"Protein Consequence\"\n",
    "    GENE_FUNC = \"Gene Function\"\n",
    "    REARRANGEMENTS = \"Rearrangements\"\n",
    "    COPY_NUMBER = \"Copy Number\"\n",
    "    OTHER = \"Other\"\n",
    "    GENOTYPES_EASY = \"Genotypes Easy\"\n",
    "    GENOTYPES_COMPOUND = \"Genotypes Compound\"\n",
    "    REGION_DEFINED_VAR = \"Region Defined Variant\"\n",
    "    TRANSCRIPT_VAR = \"Transcript Variant\"  # no attempt to normalize these ones, since there is no query we could use\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are terms in CIViC that we know that the variation normalizer cannot support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_supported = {\n",
    "    VariantCategory.EXPRESSION: {\n",
    "        \"overexpression\", \"expression\", \"underexpression\", \"serum levels\", \n",
    "        \"transcription levels\", \"autocrine activation\", \"tnc-l\", \n",
    "        \"top2a/90\", \"low ratio of vegf165b/vegftotal\", \"lgr5fl\"\n",
    "    },\n",
    "    VariantCategory.EPIGENETIC_MODIFICATION: {\n",
    "        \"methylation\", \"promoter hypermethylation\", \"promoter methylation\", \n",
    "        \"phosphorylation\"\n",
    "    },\n",
    "    VariantCategory.FUSION: {\n",
    "        \"::\", \"fusion\"\n",
    "    },\n",
    "    VariantCategory.PROTEIN_CONS: {\n",
    "        \"frameshift truncation\", \"frameshift\", \"frame shift\", \"fs\",\n",
    "        \"truncating mutation\", \"1100delc\", \"deletion (p.k227_t233del)\",\n",
    "        \"y646f, y646n, y646s, y646h, y646c, a682g, a692v\"\n",
    "    },\n",
    "    VariantCategory.GENE_FUNC: {\n",
    "        \"gain of function\", \"gain-of-function\", \"loss of function\", \"loss-of-function\",\n",
    "        \"activating mutation\", \"tkd mutation\", \"inactivation\", \"null\", \"viii\"\n",
    "    },\n",
    "    VariantCategory.REARRANGEMENTS: {\n",
    "        \"translocation\", \"rearrangement\", \"double ph\", \"alu insertion\", \n",
    "        \"exon 20 insertion\", \"internal tandem duplications\", \"tandem repeat\",\n",
    "        \"itd\", \"d842_h845deldimh\", \"k558np\"\n",
    "    },\n",
    "    VariantCategory.COPY_NUMBER: {\n",
    "        \"copy number\", \"repeat\", \"dup\", \"non-amplification\", \"gain\"\n",
    "    }, \n",
    "    VariantCategory.OTHER: {\n",
    "        \"cytoplasmic mislocalization\", \"alternative transcript\", \"rare mutation\",\n",
    "        \"splice\", \"splicing\", \"ceacam1-l\", \"ceacam1-s\", \"δ\", # this is really Δ for upper case\n",
    "        \"delta\", \"beta\", \"ivs2+1g>a\", \"ivs20, a-g, -2\",\n",
    "        \"deprecated\", \"point mutations\", \"conserved domain mut\", \"cis double mutants\",\n",
    "        \"loss-of-modification\", \"gbrcam\", \"kras4a\", \"kras4b\", \"e151int\", \"delnvtap\"\n",
    "    },\n",
    "    VariantCategory.GENOTYPES_EASY: {\n",
    "        \"diplotypes\", \"wild type\", \"wildtype\", \"p61braf(v600e)\"\n",
    "    },\n",
    "    VariantCategory.GENOTYPES_COMPOUND: {\n",
    "        \"loss of heterozygosity\", \"biallelic inactivation\", \"bi-allelic inactivation\",\n",
    "        \"homozygosity\", \"loh\", \"single allele deletion\"\n",
    "    },\n",
    "    VariantCategory.REGION_DEFINED_VAR: {\n",
    "        \"deleterious mutation\", \"domain mutation\", \"polymorphism\", \n",
    "        \"non-p-loop mutation\", \"p-loop mutation\", \"3' utr mutation\", \"alteration\",\n",
    "        \"t17 deletion\", \"exon\", \"ex19 del l858r\", \"promoter mutation\", \"non-v600\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This file contains CIViC Variants where we did not attempt to normalize\n",
    "# since we cannot find a free text or HGVS-like expression to use.\n",
    "# One example would be a CIViC Variant whose name has \"c.\" in it. In this case,\n",
    "# we want the genomic representative. We look at the HGVS expressions to find a genomic\n",
    "# expression. If there is no genomic HGVS expression, we do not even attempt to\n",
    "# normalize\n",
    "transcript_vars_wf = open(\"transcript_variants.csv\", \"w\")\n",
    "transcript_vars_wr = csv.writer(transcript_vars_wf, delimiter=\"\\t\")\n",
    "transcript_vars_wr.writerow([\"variant_id\", \"variant_name\", \"variant_accepted\"])\n",
    "\n",
    "# This file contains protein queries (gene + variant_name) we SHOULD be able to\n",
    "# normalize\n",
    "protein_variants_wf = open(\"all_protein_variant_queries.csv\", \"w\")\n",
    "protein_variants_wr = csv.writer(protein_variants_wf, delimiter=\"\\t\")\n",
    "protein_variants_wr.writerow([\"variant_id\", \"gene_name\", \"variant_name\", \"variant_accepted\"])\n",
    "\n",
    "# This file contains genomic queries (genomic HGVS expressions) we SHOULD be able to\n",
    "# normalize\n",
    "genomic_variants_wf = open(\"all_genomic_variant_queries.csv\", \"w\")\n",
    "genomic_variants_wr = csv.writer(genomic_variants_wf, delimiter=\"\\t\")\n",
    "genomic_variants_wr.writerow([\"variant_id\", \"hgvs_g\", \"variant_accepted\"])\n",
    "\n",
    "# This file contains CIViC Variants we do not currently support in Variation Normalizer.\n",
    "# In these cases, we do not even attempt to try to normalize\n",
    "not_supported_wf = open(\"not_supported_variants.csv\", \"w\")\n",
    "not_supported_wr = csv.writer(not_supported_wf, delimiter=\"\\t\")\n",
    "not_supported_wr.writerow([\"variant_id\", \"gene_name\", \"variant_name\", \"category\", \"variant_accepted\"])\n",
    "\n",
    "# This file contains CIViC Variant queries that we were not able to normalize.\n",
    "unable_to_normalize_wf = open(\"unable_to_normalize_queries.csv\", \"w\")\n",
    "unable_to_normalize_wr = csv.writer(unable_to_normalize_wf, delimiter=\"\\t\")\n",
    "unable_to_normalize_wr.writerow([\"variant_id\", \"query\", \"query_type\", \"variant_accepted\",\n",
    "                                 \"exception_raised\", \"message\", \"warnings\"])\n",
    "\n",
    "# This file contains CIViC Variant queries that we were able to normalize.\n",
    "able_to_normalize_wf = open(\"able_to_normalize_queries.csv\", \"w\")\n",
    "able_to_normalize_wr = csv.writer(able_to_normalize_wf, delimiter=\"\\t\")\n",
    "able_to_normalize_wr.writerow([\"variant_id\", \"query\", \"query_type\", \"variant_accepted\"])\n",
    "\n",
    "# Category name for variants we do not support: number of variants we found\n",
    "variant_category_counts = {c: 0 for c in VariantCategory.__members__}\n",
    "\n",
    "\n",
    "def _total_counts():\n",
    "    \"\"\"Return initial total counts for genomic and protein variants\"\"\"\n",
    "    return {\n",
    "        \"protein\": {\"accepted\": 0, \"not_accepted\": 0, \"count\": 0}, \n",
    "        \"genomic\": {\"accepted\": 0, \"not_accepted\": 0, \"count\": 0}\n",
    "    }\n",
    "\n",
    "# Keep track of total counts\n",
    "transcript_vars_total = _total_counts()\n",
    "should_be_able_to_normalize_total = _total_counts()\n",
    "can_normalize_total = _total_counts()\n",
    "unable_to_normalize_total = _total_counts()\n",
    "exception_total = _total_counts()\n",
    "\n",
    "queries_found = dict()\n",
    "\n",
    "def is_accepted_variant(v) -> bool:\n",
    "    \"\"\"Return whether or not a variant (MP) has at least one EID in an accepted status.\"\"\" \n",
    "    for mp in v.molecular_profiles:\n",
    "        for ev in mp.evidence_items:\n",
    "            if ev.status == \"accepted\":\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "for variant in variants:\n",
    "    v_name = None\n",
    "    v_q_type = None\n",
    "\n",
    "    # if a variant has at least one EID in an accepted status, it counts towards \n",
    "    # “accepted”, because that indicates review and approval of the variant as part \n",
    "    # of the evidence review\n",
    "    is_accepted = is_accepted_variant(variant)\n",
    "    accepted_key = \"accepted\" if is_accepted else \"not_accepted\"  # used in total counts dicts\n",
    "    \n",
    "    if \"c.\" in variant.name:\n",
    "        # Try getting genomic HGVS expression first\n",
    "        v_name = ([expr for expr in variant.hgvs_expressions \n",
    "                         if \"g.\" in expr] or [None])[0]\n",
    "\n",
    "        # If there is no genomic HGVS expression, try using gnomad vcf\n",
    "        if not v_name:\n",
    "            chromosome = variant.coordinates.chromosome\n",
    "            pos = variant.coordinates.start\n",
    "            ref = variant.coordinates.reference_bases\n",
    "            alt = variant.coordinates.variant_bases\n",
    "\n",
    "            if all((chromosome, pos, ref, alt)):\n",
    "                v_name = f\"{chromosome}-{pos}-{ref}-{alt}\"\n",
    "        \n",
    "        v_q_type = \"genomic\"\n",
    "    else:\n",
    "        v_name = variant.name.strip()\n",
    "        v_q_type = \"protein\"\n",
    "\n",
    "    if not v_name:\n",
    "        variant_category_counts[VariantCategory.TRANSCRIPT_VAR.name] += 1\n",
    "        transcript_vars_wr.writerow([variant.id, variant.name, is_accepted])\n",
    "        transcript_vars_total[v_q_type][\"count\"] += 1\n",
    "        transcript_vars_total[v_q_type][accepted_key] += 1\n",
    "        continue\n",
    "    \n",
    "    gene_name = variant.gene.name.strip()\n",
    "    v_name_lower = v_name.lower()\n",
    "    \n",
    "    categories = set()\n",
    "    if v_name_lower in {\"loss\", \"deletion\"}:\n",
    "        categories.add(VariantCategory.GENE_FUNC)\n",
    "    elif any((\n",
    "        v_name_lower in {\"mutation\", \"mutations\", \"snp\"},\n",
    "        v_name_lower == f\"{variant.gene.name.lower()} mutation\"\n",
    "    )):\n",
    "        categories.add(VariantCategory.REGION_DEFINED_VAR)\n",
    "    else:\n",
    "        if v_name_lower.endswith(\"deletion and mutation\"):\n",
    "            v_name_split = v_name.split()\n",
    "            if len(v_name_split) == 4:\n",
    "                if query_handler.normalize_handler.gene_normalizer.normalize(v_name_split[0]).match_type > 0:\n",
    "                    categories.add(VariantCategory.REGION_DEFINED_VAR) \n",
    "          \n",
    "        if re.match(r\".*e\\d+-e\\d+\", v_name_lower):  # ex: e20-e20\n",
    "            categories.add(VariantCategory.FUSION)\n",
    "\n",
    "        if any((\n",
    "            \"exon\" in v_name_lower,\n",
    "            re.match(r\"\\d+kb\\sdeletion\", v_name_lower),  # ex: 10kb Deletion\n",
    "            re.match(r\"partial\\sdeletion\\sof\\s\\d+(.\\d+)?\\skb\", v_name_lower),  # ex: Partial deletion of 0.7 Kb\n",
    "            re.match(r\"del\\s\\d+-\\d+\", v_name_lower),  # ex: DEL 485-490\n",
    "            re.match(r\"\\d+(p|q)\\d+(.\\d+)?-\\d+(.\\d+)?\\s\\d+mb del\", v_name_lower),  # ex: 3p26.3-25.3 11Mb del\n",
    "            re.match(r\"intron\\s\\d+\\smutation\", v_name_lower)  # ex: Intron 6 Mutation\n",
    "        )):\n",
    "            categories.add(VariantCategory.REGION_DEFINED_VAR)\n",
    "        \n",
    "        if any((\n",
    "            re.match(r\"t\\(.*\\)\\(.*\\)\", v_name_lower), # ex: t(1;3)(p36.3;p25)\n",
    "            re.match(r\".*ins$\", v_name_lower),  # ex: P780INS, L78_Q79ins\n",
    "            re.match(r\"\\w+_?\\w+>\\w+\", v_name_lower),  # ex: 56_61QKQKVG>R, E746_T751>I, N771>GY\n",
    "        )):  \n",
    "            categories.add(VariantCategory.REARRANGEMENTS)\n",
    "\n",
    "        if any((\n",
    "            re.match(r\"^rs\\d+\", v_name_lower),  # ex: RS11623866\n",
    "            re.match(r\"class\\s\\d+\\smutation\", v_name_lower),  # ex: Class 3 Mutation\n",
    "            re.match(r\"\\d+\\s\\((c|a|g|t)+-(c|a|g|t)+\\)\", v_name_lower)  # ex: 235 (CAG-TAG)\n",
    "        )):\n",
    "            categories.add(VariantCategory.OTHER)\n",
    "\n",
    "        if re.match(r\"cd\\d+v?\\d+\", v_name_lower):\n",
    "            categories.add(VariantCategory.EXPRESSION)\n",
    "\n",
    "        if any((\n",
    "            re.match(r\"\\w+\\d+$\", v_name_lower),  # ex: V600\n",
    "            re.match(r\"\\w+\\d+\\w+\\/\\w+$\", v_name_lower),  # ex: S893A/T\n",
    "            re.match(r\"[a-z]+\\d+[a-z]+\\sand\\s[a-z]+\\d+[a-z|*]+\", v_name_lower),  # ex: E2014K and E2419K, R849W and R1108*\n",
    "            re.match(r\"[a-z]+\\d+\\s&\\s[a-z]+\\d+\", v_name_lower),  # ex: D835 & I836\n",
    "            re.match(r\"[a-z]+\\d+[a-z]+\\sor\\s[a-z]+\\d+[a-z]+\", v_name_lower),  # ex: H1047L or H1047R\n",
    "            re.match(r\"\\w+\\d+\\smutations\", v_name_lower),  # ex: E1813 mutations\n",
    "        )):\n",
    "            categories.add(VariantCategory.PROTEIN_CONS)\n",
    "\n",
    "        if any((\n",
    "            re.match(r\"^\\w+\\samplification\", v_name_lower),  # ex: {gene} amplification\n",
    "            re.match(r\"grch3(7|8)\\/hg\\d+\\s\\w+.?\\d*\\(chr\\w+:\\d+-\\d+\\)x\\d+\", v_name_lower),  # ex: GRCh37/hg19 11q14.3(chr11:88960991-88961138)x160\n",
    "        )):  \n",
    "            categories.add(VariantCategory.COPY_NUMBER)\n",
    "\n",
    "        if re.match(r\"\\w+[^fs]\\*\\d+$\", v_name_lower):  # ex: UGT1A1*28\n",
    "            categories.add(VariantCategory.GENOTYPES_EASY)\n",
    "\n",
    "        for k, v in not_supported.items():\n",
    "            if {x for x in v if x in v_name_lower}:\n",
    "                categories.add(k)\n",
    "\n",
    "    if len(categories) > 1:\n",
    "        # Those with multiple categories will be classified as other\n",
    "        categories = {VariantCategory.OTHER}\n",
    "\n",
    "    if len(categories) == 1:\n",
    "        variant_category_name = categories.pop()\n",
    "        variant_category_counts[variant_category_name.name] += 1\n",
    "        not_supported_wr.writerow([variant.id, gene_name, variant.name, variant_category_name, is_accepted])\n",
    "    else:\n",
    "        # We should support this, so we need to query the variation normalizer\n",
    "        if v_q_type == \"protein\":\n",
    "            q = f\"{gene_name} {v_name}\"\n",
    "            protein_variants_wr.writerow([variant.id, gene_name, v_name, is_accepted])\n",
    "        else:\n",
    "            q = v_name\n",
    "            genomic_variants_wr.writerow([variant.id, q, is_accepted])\n",
    "\n",
    "        should_be_able_to_normalize_total[v_q_type][\"count\"] += 1\n",
    "        should_be_able_to_normalize_total[v_q_type][accepted_key] += 1\n",
    "\n",
    "        if q in queries_found:\n",
    "            queries_found[q].append(variant.id)\n",
    "        else:\n",
    "            queries_found[q] = [variant.id]\n",
    "            \n",
    "        try:\n",
    "            variation_norm_resp = await query_handler.normalize_handler.normalize(q)\n",
    "            if not variation_norm_resp.variation_descriptor:\n",
    "                is_incomplete = False\n",
    "                if v_q_type == \"protein\" and len(v_name.split()) == 1:\n",
    "                    if \"-\" in v_name:\n",
    "                        # could be {gene}-{gene}\n",
    "                        genes = v_name.split(\"-\")\n",
    "                        variant_category_name = VariantCategory.FUSION\n",
    "                    else:\n",
    "                        # Just a gene name\n",
    "                        genes = [v_name]\n",
    "                        variant_category_name = VariantCategory.OTHER\n",
    "\n",
    "                    is_genes = True\n",
    "                    for g in genes:\n",
    "                        if query_handler.normalize_handler.gene_normalizer.normalize(g).match_type == 0:\n",
    "                            # not a gene \n",
    "                            is_genes = False\n",
    "                            break\n",
    "\n",
    "                    if is_genes:\n",
    "                        variant_category_counts[variant_category_name.name] += 1\n",
    "                        not_supported_wr.writerow([variant.id, gene_name, variant.name, variant_category_name, is_accepted])\n",
    "                        is_incomplete = True\n",
    "\n",
    "                if not is_incomplete:\n",
    "                    unable_to_normalize_wr.writerow([variant.id, q, v_q_type, \n",
    "                                                    is_accepted, False,\n",
    "                                                    \"unable to normalize\",\n",
    "                                                    variation_norm_resp.warnings])\n",
    "                    unable_to_normalize_total[v_q_type][\"count\"] += 1\n",
    "                    unable_to_normalize_total[v_q_type][accepted_key] += 1\n",
    "            else:\n",
    "                can_normalize_total[v_q_type][\"count\"] += 1\n",
    "                can_normalize_total[v_q_type][accepted_key] += 1\n",
    "                able_to_normalize_wr.writerow([variant.id, q, v_q_type, is_accepted])\n",
    "        except Exception as e:\n",
    "            unable_to_normalize_wr.writerow([variant.id, q, v_q_type, is_accepted,\n",
    "                                             True, str(e), None])\n",
    "            exception_total[v_q_type][\"count\"] += 1\n",
    "            exception_total[v_q_type][accepted_key] += 1\n",
    "\n",
    "# Close all files\n",
    "transcript_vars_wf.close()\n",
    "protein_variants_wf.close()\n",
    "genomic_variants_wf.close()\n",
    "not_supported_wf.close()\n",
    "unable_to_normalize_wf.close()\n",
    "able_to_normalize_wf.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants we do not support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_not_support_total_sum = sum(variant_category_counts.values())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the total number of variants for each category that we do not support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRANSCRIPT_VAR': 384,\n",
       " 'FUSION': 301,\n",
       " 'EXPRESSION': 291,\n",
       " 'REGION_DEFINED_VAR': 190,\n",
       " 'PROTEIN_CONS': 128,\n",
       " 'OTHER': 92,\n",
       " 'GENE_FUNC': 87,\n",
       " 'REARRANGEMENTS': 50,\n",
       " 'COPY_NUMBER': 34,\n",
       " 'EPIGENETIC_MODIFICATION': 15,\n",
       " 'GENOTYPES_EASY': 10,\n",
       " 'GENOTYPES_COMPOUND': 6}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_variant_cat_counts = dict(sorted(variant_category_counts.items(), key=lambda x: x[1], reverse=True))\n",
    "sorted_variant_cat_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the total percentage of variants for each category that we do not support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRANSCRIPT_VAR': '10.94%',\n",
       " 'FUSION': '8.58%',\n",
       " 'EXPRESSION': '8.29%',\n",
       " 'REGION_DEFINED_VAR': '5.41%',\n",
       " 'PROTEIN_CONS': '3.65%',\n",
       " 'OTHER': '2.62%',\n",
       " 'GENE_FUNC': '2.48%',\n",
       " 'REARRANGEMENTS': '1.42%',\n",
       " 'COPY_NUMBER': '0.97%',\n",
       " 'EPIGENETIC_MODIFICATION': '0.43%',\n",
       " 'GENOTYPES_EASY': '0.28%',\n",
       " 'GENOTYPES_COMPOUND': '0.17%'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: f\"{v / total_variants * 100:.2f}%\" for k, v in sorted_variant_cat_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer does not support 45.26% of the total variants'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer does not support {do_not_support_total_sum / total_variants * 100:.2f}% of the total variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Total number of variants we do not support in the Variation Normalizer: 1588'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Total number of variants we do not support in the Variation Normalizer: \"\\\n",
    "f\"{do_not_support_total_sum}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript Variants we did not attempt to normalize due to no input query available \n",
    "These are CIViC Variants where we did not attempt to normalize since we cannot find a \n",
    "free text or HGVS-like expression to use. One example would be a CIViC Variant whose \n",
    "name has \"c.\" in it. In this case, we want the genomic representative. We look at the \n",
    "HGVS expressions to find a genomic expression. If there is no genomic HGVS expression, \n",
    "we do not even attempt to normalize. These are under the Transcript Variant category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein': {'accepted': 0, 'not_accepted': 0, 'count': 0},\n",
       " 'genomic': {'accepted': 51, 'not_accepted': 333, 'count': 384}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_vars_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_vars_total_sum = transcript_vars_total[\"protein\"][\"count\"] + transcript_vars_total[\"genomic\"][\"count\"]\n",
    "transcript_vars_total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13.28% of these are accepted variants'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_vars_total_accepted = transcript_vars_total[\"protein\"][\"accepted\"] + transcript_vars_total[\"genomic\"][\"accepted\"]\n",
    "f\"{transcript_vars_total_accepted / transcript_vars_total_sum * 100:.2f}% of these are accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'86.72% of these are NOT accepted variants'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_vars_total_not_accepted = transcript_vars_total[\"protein\"][\"not_accepted\"] + transcript_vars_total[\"genomic\"][\"not_accepted\"]\n",
    "f\"{transcript_vars_total_not_accepted / transcript_vars_total_sum * 100:.2f}% of these are NOT accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.94% of the total variants were not attempted to be normalized due to no input query available'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{transcript_vars_total_sum / total_variants * 100:.2f}% of the total variants were not attempted to be normalized due to no input query available\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants we should be able to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein': {'accepted': 631, 'not_accepted': 872, 'count': 1503},\n",
       " 'genomic': {'accepted': 245, 'not_accepted': 179, 'count': 424}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_be_able_to_normalize_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1927"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_be_able_to_normalize_total_sum = should_be_able_to_normalize_total[\"protein\"][\"count\"] + should_be_able_to_normalize_total[\"genomic\"][\"count\"]\n",
    "should_be_able_to_normalize_total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'45.46% of these are accepted variants'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_be_able_to_normalize_total_accepted = should_be_able_to_normalize_total[\"protein\"][\"accepted\"] + should_be_able_to_normalize_total[\"genomic\"][\"accepted\"]\n",
    "f\"{should_be_able_to_normalize_total_accepted / should_be_able_to_normalize_total_sum * 100:.2f}% of these are accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'54.54% of these are NOT accepted variants'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "should_be_able_to_normalize_total_not_accepted = should_be_able_to_normalize_total[\"protein\"][\"not_accepted\"] + should_be_able_to_normalize_total[\"genomic\"][\"not_accepted\"]\n",
    "f\"{should_be_able_to_normalize_total_not_accepted / should_be_able_to_normalize_total_sum * 100:.2f}% of these are NOT accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer SHOULD be able to normalize 54.92% of the total variants'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer SHOULD be able to normalize {should_be_able_to_normalize_total_sum / total_variants * 100:.2f}% of the total variants\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants we were not able to normalize\n",
    "\n",
    "Either due to a bug or an unsupported query type in Variation Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein': {'accepted': 8, 'not_accepted': 52, 'count': 60},\n",
       " 'genomic': {'accepted': 1, 'not_accepted': 2, 'count': 3}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unable_to_normalize_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unable_to_normalize_total_sum = unable_to_normalize_total[\"protein\"][\"count\"] + unable_to_normalize_total[\"genomic\"][\"count\"]\n",
    "unable_to_normalize_total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14.29% of these are accepted variants'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unable_to_normalize_total_accepted = unable_to_normalize_total[\"protein\"][\"accepted\"] + unable_to_normalize_total[\"genomic\"][\"accepted\"]\n",
    "f\"{unable_to_normalize_total_accepted / unable_to_normalize_total_sum * 100:.2f}% of these are accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85.71% of these are NOT accepted variants'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unable_to_normalize_total_not_accepted = unable_to_normalize_total[\"protein\"][\"not_accepted\"] + unable_to_normalize_total[\"genomic\"][\"not_accepted\"]\n",
    "f\"{unable_to_normalize_total_not_accepted / unable_to_normalize_total_sum * 100:.2f}% of these are NOT accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer was unable to normalize 1.7953833000854944% of the total variants'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer was unable to normalize {unable_to_normalize_total_sum / total_variants * 100}% of the total variants\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of the variants we weren't able to normalize\n",
    "\n",
    "In this section, we breakdown the reasons on why we weren't able to normalize variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "unable_to_tokenize = 0\n",
    "unable_to_find_valid = 0\n",
    "other = 0\n",
    "with open(\"unable_to_normalize_queries.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        if \"Unable to find valid result\" in row[-1]:\n",
    "            unable_to_find_valid += 1\n",
    "        elif \"Unable to tokenize\" in row[-1]:\n",
    "            unable_to_tokenize += 1\n",
    "        else:\n",
    "            other += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to not passing validation checks\n",
    "\n",
    "The Variation Normalizer performs validation checks on the input query (such as reference sequence). If these validation checks fail, then the input query will fail to normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer found 62 invalid variants (This is 1.77% of the total variants).'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer found {unable_to_find_valid} invalid variants (This is {unable_to_find_valid / total_variants * 100:.2f}% of the total variants).\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to tokenization \n",
    "\n",
    "The Variation Normalizer will tokenize the input query to determine the kind of token. It is limited in the kinds of tokens it accepts, so these tokens are not yet supported in the Variation Normalizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer was unable to tokenize 1 variants (0.03% of the total variants).'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer was unable to tokenize {unable_to_tokenize} variants ({unable_to_tokenize / total_variants * 100:.2f}% of the total variants).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer was unable to normalize 0 variants due to other issues (This is 0.00% of the total variants).'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer was unable to normalize {other} variants due to other issues (This is {other / total_variants * 100:.2f}% of the total variants).\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant queries that raised an exception during normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein': {'accepted': 0, 'not_accepted': 0, 'count': 0},\n",
       " 'genomic': {'accepted': 0, 'not_accepted': 0, 'count': 0}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exception_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exception_total_sum = exception_total[\"protein\"][\"count\"] + exception_total[\"genomic\"][\"count\"]\n",
    "exception_total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer raised an exception for 0.00% of the total variants'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer raised an exception for {exception_total_sum / total_variants * 100:.2f}% of the total variants\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variants we were able to normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'protein': {'accepted': 621, 'not_accepted': 816, 'count': 1437},\n",
       " 'genomic': {'accepted': 244, 'not_accepted': 177, 'count': 421}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_normalize_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1858"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_normalize_total_sum = can_normalize_total[\"protein\"][\"count\"] + can_normalize_total[\"genomic\"][\"count\"]\n",
    "can_normalize_total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46.56% of these are accepted variants'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_normalize_total_accepted = can_normalize_total[\"protein\"][\"accepted\"] + can_normalize_total[\"genomic\"][\"accepted\"]\n",
    "f\"{can_normalize_total_accepted / can_normalize_total_sum * 100:.2f}% of these are accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'53.44% of these are NOT accepted variants'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "can_normalize_total_not_accepted = can_normalize_total[\"protein\"][\"not_accepted\"] + can_normalize_total[\"genomic\"][\"not_accepted\"]\n",
    "f\"{can_normalize_total_not_accepted / can_normalize_total_sum * 100:.2f}% of these are NOT accepted variants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer successfully normalized 96.42% of the variants we SHOULD be able to normalize'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer successfully normalized {can_normalize_total_sum / should_be_able_to_normalize_total_sum * 100:.2f}% of the variants we SHOULD be able to normalize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Variation Normalizer successfully normalized 52.95% of the total variants'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"The Variation Normalizer successfully normalized {can_normalize_total_sum / total_variants * 100:.2f}% of the total variants\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Queries\n",
    "\n",
    "These are duplicate queries found in civic. The values are the associated variant IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRAF V600D': [11, 3452]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k:v for k,v in queries_found.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "variation-normalization-KPVKcmjd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0be8ba9a7b89517724a412b9d40e184059795303560bd1108143a8aed13113be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
